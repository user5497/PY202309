{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f996814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 쿼리를 입력하세요.Hello\n",
      "There is no similar sentence.\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "# 문장의 양옆 공백을 제거하고 띄어쓰기를 기준으로 나누는 전처리를 진행합니다. \n",
    "def preprocess(sentence):\n",
    "    preprocessed_sentence=sentence.strip().split(\" \") \n",
    "    return preprocessed_sentence\n",
    "\n",
    "# 인덱싱을 진행합니다. \n",
    "def indexing(file_name):\n",
    "    file_tokens_pairs=[]\n",
    "    # file의 문장들 전부를 읽기 형식으로 가져옵니다. \n",
    "    lines=open(file_name,\"r\",encoding=\"utf8\").readlines() \n",
    "    for line in lines:\n",
    "        tokens=preprocess(line) # 문장 line에 대해 전처리 진행\n",
    "        file_tokens_pairs.append(tokens) \n",
    "    return file_tokens_pairs\n",
    "\n",
    "# 유사도를 계산합니다.\n",
    "def calc_similarity(preprocessed_query,preprocessed_sentences):\n",
    "    # preprocessed_query = query_token_set, preprocessed_sentences = file_tokens_pairs 대입\n",
    "    score_dict={}\n",
    "    for i in range(len(preprocessed_sentences)): # 파일의 문장 수만큼 비교\n",
    "        sentences_set = set(preprocessed_sentences[i]) # set으로 전환\n",
    "        sentence = preprocessed_sentences[i] # 원형 저장\n",
    "        query_str = ' '.join(preprocessed_query).lower() # 대소문자 구분을 없애기 위해서 lower().\n",
    "        sentence_str = ' '.join(sentence).lower()\n",
    "        preprocessed_query = set(preprocess(query_str)) # 전처리 진행 및 중복 삭제  \n",
    "        preprocessed_sentence = preprocess(sentence_str)   \n",
    "        \n",
    "        file_token_set = set(preprocessed_sentence)\n",
    "        all_tokens = preprocessed_query | file_token_set\n",
    "        same_tokens = preprocessed_query & file_token_set\n",
    "        # 같은 tokens의 수와 모든 토큰을 비교하여 유사도 측정\n",
    "        similarity = len(same_tokens) / len(all_tokens)  \n",
    "        score_dict[i] = similarity \n",
    "    return score_dict\n",
    "\n",
    "# 전처리 진행\n",
    "file_name = \"jhe-koen-dev.en.txt\"\n",
    "file_tokens_pairs = indexing(file_name)\n",
    "\n",
    "# 쿼리 입력\n",
    "query = input(\"영어 쿼리를 입력하세요.\")\n",
    "preprocessed_query = preprocess(query)\n",
    "query_token_set = set(preprocessed_query) # 전처리된 query를 set 형태로 저장\n",
    "\n",
    "# 3. 토큰 셋을 기준으로 유사도를 측정\n",
    "score_dict = calc_similarity(query_token_set,file_tokens_pairs)\n",
    "\n",
    "# 4. 유사도 리스트를 정렬합니다. \n",
    "sorted_score_list = sorted(score_dict.items(), key = operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# 5. 결과를 출력합니다. \n",
    "if sorted_score_list[0][1] == 0.0:\n",
    "    print(\"There is no similar sentence.\")\n",
    "else:\n",
    "    print(\"rank\", \"Index\", \"score\", \"sentence\", sep = \"\\t\")\n",
    "    rank = 1\n",
    "    for i, score  in sorted_score_list:\n",
    "        print(rank, i, score, ' '.join(file_tokens_pairs[i]), sep = \"\\t\")\n",
    "        if rank == 10:\n",
    "            break\n",
    "        rank = rank + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
